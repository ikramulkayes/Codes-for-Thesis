{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68f10428-72f2-4b7c-b21b-c3fc67fc2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "823a6f07-fe53-49bf-9fd8-319aa99f8253",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '500to1100.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d38a4d75-f8c8-4316-8ad7-b6da8eacdceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1c94bb7-1c00-42ab-a64e-b3ff9fb1122c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row of the 'Predicted Answer' column:\n",
      "Output:\n",
      "<think>\n",
      "Okay, I need to figure out the answer to the question: \"প্রস্তাবনা অনুযায়ী কেমিস্ট্রি শব্দের প্রথম দিকের বানান মূলত কী বোঝায়?\" which translates to \"According to the proposal, what does the original form of the word 'chemistry' mean?\"\n",
      "\n",
      "First, I'll look at the context provided. The context discusses the terms \"আরবি\", \"ইসলামিক\", \"আলকেমি\", and \"রসায়ন\" and their definitions. It mentions that the word \"কেমিস্ট্রি\" (chemistry) comes from \"আলকেমি\" (alchemy). Specifically, it says that the original form of \"কেমিস্ট্রি\" is \"আলকেমি\" and that early chemistry was included in this unified science.\n",
      "\n",
      "So, the contextual answer should be that the original form of \"chemistry\" is \"আলকেমি\".\n",
      "\n",
      "For the parametric answer, I know from general knowledge that \"chemistry\" indeed originates from \"alchemy\". Alchemy was an early form of the science, focusing on transforming base metals into noble ones and finding the elixir of life. Over time, it evolved into modern chemistry. Therefore, the parametric answer also points to \"আলকেমি\" as the origin of the word \"chemistry\".\n",
      "</think>\n",
      "\n",
      "Contextual Answer: \"আলকেমি।\"\n",
      "\n",
      "Parametric Answer: \"আলকেমি।\"\n",
      "\n",
      "Reasoning:\n",
      "\n",
      "The context explicitly states that the original form of the word \"chemistry\" is \"alchemy,\" so the contextual answer is \"আলকেমি।\" Based on my knowledge, \"chemistry\" indeed originates from \"alchemy,\" confirming the parametric answer as \"আলকেমি।\"\n",
      "\n",
      "End of thought process\n",
      "\n",
      "Contextual Answer: \"আলকেমি।\"\n",
      "Parametric Answer: \"আলকেমি।\"\n",
      "Explanation:\n",
      "\"আলকেমি।\"\n"
     ]
    }
   ],
   "source": [
    "# # Print the 'Predicted Answer' column\n",
    "# print(\"Predicted Answer Column:\")\n",
    "# print(df['Predicted Answer'])\n",
    "\n",
    "# Print the first row of the 'Predicted Answer' column\n",
    "print(\"First row of the 'Predicted Answer' column:\")\n",
    "print(df['Predicted Answer'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7ee0eff1-b6c2-4f0f-ab0a-b3da782e4690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"End of thought process\" appears 440 times in the \"Predicted Answer\" column.\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of the sentence \"End of thought process\"\n",
    "sentence_to_count = \"End of thought process\"\n",
    "count = df['Predicted Answer'].str.contains(sentence_to_count, na=False).sum()\n",
    "\n",
    "print(f'The sentence \"{sentence_to_count}\" appears {count} times in the \"Predicted Answer\" column.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fa1ff003-dac8-4b56-8f0a-a83f583af885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Context  \\\n",
      "0  ইসলামী বিজ্ঞানকে একটি স্বতন্ত্র, স্থানীয় বৈজ্...   \n",
      "1  ইসলামী বিজ্ঞানকে একটি স্বতন্ত্র, স্থানীয় বৈজ্...   \n",
      "2  ইসলামী বিজ্ঞানকে একটি স্বতন্ত্র, স্থানীয় বৈজ্...   \n",
      "3  ইসলামী বিজ্ঞানকে একটি স্বতন্ত্র, স্থানীয় বৈজ্...   \n",
      "4  ইসলামী বিজ্ঞানকে একটি স্বতন্ত্র, স্থানীয় বৈজ্...   \n",
      "\n",
      "                                            Question  \\\n",
      "0                      ক্রিয়োসোপিয়া বলতে কী বুঝায়?   \n",
      "1  প্রস্তাবনা অনুযায়ী কেমিস্ট্রি শব্দের প্রথম দিক...   \n",
      "2  প্রস্তাবনা অনুযায়ী কেমিস্ট্রি শব্দের প্রথম দিক...   \n",
      "3  সপ্তদশ শতাব্দীর শেষভাগে সাধারণভাবে কাকে দেখা হ...   \n",
      "4  সপ্তদশ শতাব্দীর শেষভাগে সাধারণভাবে কাকে দেখা হ...   \n",
      "\n",
      "                                              Answer  \\\n",
      "0  parametric answer: ধাতুকে অন্য পদার্থে রূপান্ত...   \n",
      "1  parametric answer: আলকেমি এবং প্রথম দিকের রসায...   \n",
      "2  parametric answer: আলকেমি এবং প্রথম দিকের রসায...   \n",
      "3  parametric answer: ক্রিয়োসোপিয়া\\ncontextual ...   \n",
      "4  parametric answer: ক্রিয়োসোপিয়া\\ncontextual ...   \n",
      "\n",
      "                                    Predicted Answer  \n",
      "0  Contextual Answer: \"ক্রিয়োসোপিয়া\" বলতে ধাতুক...  \n",
      "1  Contextual Answer: \"আলকেমি।\"\\nParametric Answe...  \n",
      "2  Contextual Answer: কেমিস্ট্রি শব্দের প্রথম দিক...  \n",
      "3  Contextual Answer: আলকেমি।\\nParametric Answer:...  \n",
      "4  Contextual Answer: আলকেমি।\\nParametric Answer:...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the regex pattern to match text after </think>\n",
    "after_think_pattern = r\"</think>\\s*(.*)\"\n",
    "\n",
    "# Define a function to clean and extract only Contextual and Parametric answers, removing extra text after the answers\n",
    "def extract_clean_answers(answer):\n",
    "    # Handle NaN or non-string values gracefully\n",
    "    if pd.isna(answer):\n",
    "        return \"\"\n",
    "\n",
    "    # Ensure the answer is a string\n",
    "    answer = str(answer)\n",
    "\n",
    "    # Extract text after </think>\n",
    "    after_think_match = re.search(after_think_pattern, answer, re.DOTALL)\n",
    "    if not after_think_match:\n",
    "        return \"\"  # Return empty string if </think> not found\n",
    "\n",
    "    # Get text after </think>\n",
    "    after_think_text = after_think_match.group(1)\n",
    "\n",
    "    # Extract Contextual and Parametric answers, stopping at the next label or end of text\n",
    "    contextual_answer_pattern = r\"Contextual Answer:\\s*(.*?)(?=(Parametric Answer:|Reasoning:|Explanation:|$))\"\n",
    "    parametric_answer_pattern = r\"Parametric Answer:\\s*(.*?)(?=(Reasoning:|Explanation:|$))\"\n",
    "\n",
    "    contextual_match = re.search(contextual_answer_pattern, after_think_text, re.DOTALL)\n",
    "    parametric_match = re.search(parametric_answer_pattern, after_think_text, re.DOTALL)\n",
    "\n",
    "    contextual_answer = f\"Contextual Answer: {contextual_match.group(1).strip()}\" if contextual_match else \"\"\n",
    "    parametric_answer = f\"Parametric Answer: {parametric_match.group(1).strip()}\" if parametric_match else \"\"\n",
    "\n",
    "    # Combine and return only Contextual and Parametric answers\n",
    "    return \"\\n\".join(filter(None, [contextual_answer, parametric_answer]))\n",
    "\n",
    "# Apply the function to the \"Predicted Answer\" column\n",
    "df['Predicted Answer'] = df['Predicted Answer'].apply(extract_clean_answers)\n",
    "\n",
    "# Output for verification\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b05cb4-2064-4a21-b690-af54755148ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225b9e4a-d34f-440b-8db4-8cc406af419a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e058307d-280f-4edb-9c33-3e6b626bf651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contextual Answer: হ্যাঁ, একটি শর্ট সার্কিট যখন খুব বড় তড়িৎপ্রবাহ তৈরি করে তখন গাড়ির ব্যাটারি বিস্ফোরিত হতে পারে।\n",
      "Parametric Answer: হ্যাঁ, শর্ট সার্কিট ব্যাটারিকে বিস্ফোরণ করতে পারে।\n"
     ]
    }
   ],
   "source": [
    "print(df['Predicted Answer'].iloc[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d220c3f-11e9-4332-a7dc-a29bc8ad8f19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499]\n"
     ]
    }
   ],
   "source": [
    "print(missing_start_sentence_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94600431-b173-4c64-8e81-cc5a7643a5ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f629b6-a97c-4e26-862a-6d5b366a9645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534d3c08-4fc2-433d-928f-7b1fb15de9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2999089e-d70b-4111-9bdb-2ae3df039438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install google-generativeai python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4676f88a-ab07-453a-9474-e38f31221a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ce9c98-ec9c-425d-bfe1-d4d46e2b1291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6cf841-d43d-4246-a6ec-8f67a1a51250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4618b316-5a6a-4181-add8-b9817d1ec2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data with updated answers has been saved to processed_700to1100.csv\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import google.generativeai as genai\n",
    "# from time import sleep\n",
    "\n",
    "# # Configure the Gemini API\n",
    "# genai.configure(api_key=\"\")\n",
    "# model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "\n",
    "\n",
    "\n",
    "# # Function to extract answers using Gemini\n",
    "# def extract_answers(predicted_answer):\n",
    "#     if not predicted_answer.strip():\n",
    "#         return \"\"\n",
    "    \n",
    "#     prompt = f'''\n",
    "#     {predicted_answer}\n",
    "    \n",
    "#     From the text only extract the Parametric and Contextual answers only, If you are unable to extact return None and follow the format bellow.\n",
    "\n",
    "#     Format:\n",
    "#     Contextual Answer:\n",
    "#     Parametric Answer:\n",
    "#     '''\n",
    "\n",
    "#     response = model.generate_content(prompt)\n",
    "#     return response.text\n",
    "\n",
    "# # Process only the rows with missing start sentence\n",
    "# for idx in missing_start_sentence_indices:\n",
    "#     updated_answer = extract_answers(df.at[idx, 'Predicted Answer'])\n",
    "#     df.at[idx, 'Predicted Answer'] = updated_answer\n",
    "#     sleep(10)\n",
    "\n",
    "# # Save the updated DataFrame to a new CSV file\n",
    "# output_file_path = 'processed_700to1100.csv'\n",
    "# df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# print(f\"Processed data with updated answers has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "93b055a4-188b-414b-b556-e547cf5e4f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data with updated answers has been saved to processed_500to1100.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the updated DataFrame to a new CSV file\n",
    "output_file_path = 'processed_500to1100.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Processed data with updated answers has been saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecaa93f-a53f-4859-8642-b4742ada4cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeabf5b-9ee4-4256-b1ef-784809bf9950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contextual Answer: ২০৪৩\n",
      "Parametric Answer: প্রায় ২০০৯ সাল থেকে, যদিও স্বতন্ত্র ডেভেলপারদের কাজ আগেও ছিল।\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"\")\n",
    "model = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "\n",
    "response = model.generate_content('''\n",
    "**Contextual Answer**: ২০৪৩\n",
    "\n",
    "**Parametric Answer**: প্রায় ২০০�9 সাল থেকে, যদিও স্বতন্ত্র ডেভেলপারদের কাজ আগেও ছিল।\n",
    "\n",
    "\n",
    "In the above section extact the Contextual and Parametric Answer only\n",
    "Translate it to Bengali do not add anything extra and change anything. Keep the digits same! Converts English degits to Bengali Digits!\n",
    "\n",
    "Format:\n",
    "Contextual Answer:\n",
    "Parametric Answer:\n",
    "''')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beabf1ab-34e4-47a7-b0b8-fb21f468e5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea8f6f-d9cb-4a8c-9f9d-edfbfdc0e20f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6dcdc-fb70-4156-85ac-76244b7991ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5b412-252b-460d-a62f-d7dfb390cf33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84137fff-35fe-444a-8105-6415d40b7f05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ebe8d5-14e6-4877-a153-69a2cd14ea88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b5922-f4a3-40b5-8cd0-bf8301f477a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2679440f-a6d9-47c0-a6bd-c20586359899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d65791e-2a40-4afe-8ef8-102119ea1075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e0cad-4837-4ba7-856a-df7d9495a56e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5f83a4-8744-4541-8912-d0e27fcc45b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07606aeb-dec1-4daf-8c19-49ee1c73d5f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867a896-fb5b-4c6a-ae28-1c6236d9bce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a8b4d5-de0e-442b-aaad-0bec9280dd9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234ae85f-448c-4460-8ea8-18425db2a672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94ab4a-7325-4952-a23e-464f1344614b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee833195-bbbf-4756-81b1-16dcf7490935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b2015-2083-43b9-92d9-8cfa47816acf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1040c59-cf6d-4409-a91a-030cd0339309",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
